{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#use a fixed seed for reproducibility\n",
    "#seed = np.random.randint(10000, size=1)[0]\n",
    "#print(seed)\n",
    "seed = 6016\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 1. load data\n",
    "############################################################\n",
    "\n",
    "# load dataset\n",
    "print(\"Loading data...\")\n",
    "dataframe = pd.read_csv(\"join.txt\", header=None)\n",
    "print(\"Loaded...\")\n",
    "dataset = dataframe.values\n",
    "del dataframe # this thing is very large\n",
    "\n",
    "num_obs, num_features = dataset.shape\n",
    "num_features -=1\n",
    "num_labels=1\n",
    "print(\"Observations: %d\\nFeatures: %d\" % (num_obs, num_features))\n",
    "\n",
    "# last column is target \n",
    "y=dataset[:,num_features].astype(float)\n",
    "print(\"Histogram: check all 0s and 1s, no -1s etc.\")\n",
    "pprint(np.histogram(y))\n",
    "\n",
    "# omit 1st id column\n",
    "X = dataset[:,1:num_features].astype(float)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2122"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into training, temp\n",
      "Split into xval, test\n",
      "Training set\n",
      "(380459, 2122)\n",
      "(array([370423,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,  10036]),\n",
      " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]))\n",
      "Xval set\n",
      "(126820, 2122)\n",
      "(array([123479,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,   3341]),\n",
      " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]))\n",
      "Test set\n",
      "(126820, 2122)\n",
      "(array([123485,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,   3335]),\n",
      " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]))\n"
     ]
    }
   ],
   "source": [
    "X = scale(X)\n",
    "\n",
    "print(\"Split into training, temp\")\n",
    "num_features -=1\n",
    "# split into training, xval, test, 60/20/20\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4)\n",
    "print(\"Split into xval, test\")\n",
    "X_xval, X_test, y_xval, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "del X\n",
    "del X_temp\n",
    "del y_temp\n",
    "\n",
    "print \"Training set\"\n",
    "print X_train.shape\n",
    "pprint(np.histogram(y_train))\n",
    "\n",
    "print \"Xval set\"\n",
    "print X_xval.shape\n",
    "pprint(np.histogram(y_xval))\n",
    "\n",
    "print \"Test set\"\n",
    "print X_test.shape\n",
    "pprint(np.histogram(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.75   1.41   1.74   2.05   2.31   2.53   2.72   2.91   3.09   3.27\n",
      "   3.43   3.58   3.72   3.85   3.98   4.11   4.24   4.36   4.48   4.6\n",
      "   4.72   4.83   4.94   5.05   5.16   5.27   5.37   5.47   5.57   5.67\n",
      "   5.77   5.87   5.97   6.07   6.17   6.26   6.35   6.44   6.53   6.62\n",
      "   6.71   6.8    6.89   6.98   7.07   7.16   7.25   7.34   7.43   7.52\n",
      "   7.61   7.69   7.77   7.85   7.93   8.01   8.09   8.17   8.25   8.33\n",
      "   8.41   8.49   8.57   8.65   8.73   8.81   8.89   8.97   9.05   9.13\n",
      "   9.21   9.29   9.37   9.45   9.53   9.61   9.69   9.77   9.85   9.93\n",
      "  10.01  10.09  10.17  10.24  10.31  10.38  10.45  10.52  10.59  10.66\n",
      "  10.73  10.8   10.87  10.94  11.01  11.08  11.15  11.22  11.29  11.36]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fadbf633e90>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEfFzCnoRET+noBcR8XMKehERP/f/ATHuDYWiEVm9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadab86e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scree chart to see how much variation is explained by how many predictors\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=num_features)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1[:100])\n",
    "\n",
    "#print(var1)\n",
    "%matplotlib inline\n",
    "plt.plot(var1)\n",
    "\n",
    "# looks like ~100 orthogonal PCA components explain > 50% of the variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a custom f-score metric\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # return keras tensor for recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # return keras tensor for precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def f_score(y_true, y_pred):\n",
    "    beta = 2 # penalize false positives\n",
    "    return fbeta_score(y_true, y_pred, beta=2)\n",
    "    #my_precision = precision(y_true, y_pred)\n",
    "    #my_recall = recall(y_true, y_pred)\n",
    "    \n",
    "    #f_score = (1 +( beta **2)) * my_precision * my_recall / ((beta ** 2) * my_precision + my_recall)\n",
    "\n",
    "#def my_score(estimator, X, y):\n",
    "#    predict y_pred using X\n",
    "##    error_score = false_pos * 2 + false_neg \n",
    "#    if error_score > len(X) return 0\n",
    "#    else return 1 - error_score/len(X)\n",
    "\n",
    "\n",
    "# function to generate model\n",
    "def create_model(hidden_layer_size=30, dropout=(2.0/3.0), reg_penalty=0.0001):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_size, \n",
    "                    input_dim=num_features, \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(reg_penalty)\n",
    "                   ))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f_score])\n",
    "    return model\n",
    "\n",
    "def selectThreshold (logits, labels, beta=1):\n",
    "    # return threshold, f-score that yields best F-score\n",
    "    # predict using true if >= threshold\n",
    "\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(labels, logits)\n",
    "    f1_scores = (1 +( beta **2)) * precision * recall / ((beta ** 2) * precision + recall)\n",
    "    best_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_index]\n",
    "    best_score = f1_scores[best_index]\n",
    "    return (best_threshold, best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('%s Starting' % time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# minimize a raw score\n",
    "# show correct metric\n",
    "# pick threshold using correct metric\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "hidden_layer_hp = [30]\n",
    "dropout_hp = [0.333]\n",
    "reg_penalty_hp = [0.0001, 0.00001, 0.001]\n",
    "class_weight1= {0: 1.0, 1: 1.0}\n",
    "class_weight2= {0: 1.0, 1: 2.0}\n",
    "class_weight3 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weight_hp = [class_weight2, class_weight3]\n",
    "\n",
    "param_grid = dict(hidden_layer_size=hidden_layer_hp, \n",
    "                  dropout=dropout_hp, \n",
    "                  reg_penalty=reg_penalty_hp,\n",
    "                  class_weight=class_weight_hp)\n",
    "\n",
    "#grid = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=kfold, n_jobs=-1)\n",
    "#classifier = grid.fit(X_train, y_train)\n",
    "\n",
    "#GridSearchCV is annoying to use with custom metric to choose best, sted accuracy\n",
    "#would like to do k-fold CV and average raw error but not clear how to do that\n",
    "#also would like output after each iteration\n",
    "\n",
    "for hl in hidden_layer_hp:\n",
    "    for dr in dropout_hp:\n",
    "        for rp in reg_penalty_hp:\n",
    "            count=1\n",
    "            for cw in class_weight_hp:\n",
    "                count+=1\n",
    "                print(\"\\n%s Hidden layer: %d, Dropout: %.4f, Regularization %.8f, class weight: %d\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"), hl, dr, rp, count))               \n",
    "                classifier = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0,\n",
    "#                                        cv=kfold,\n",
    "                                        hidden_layer_size=hl, \n",
    "                                        dropout=dr, \n",
    "                                        reg_penalty=rp,\n",
    "                                        class_weight=cw\n",
    "                                       )\n",
    "                classifier.fit(X_train, y_train)\n",
    "                                \n",
    "                y_xval_proba = classifier.predict_proba(X_xval)[:,1]\n",
    "                thresh, score = selectThreshold(y_xval_proba, y_xval, beta=(2.0/3))\n",
    "                y_xval_pred = y_xval_proba >= thresh\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                true_negatives = confusion_matrix[0][0]\n",
    "                false_negatives = confusion_matrix[0][1]\n",
    "                false_positives = confusion_matrix[1][0]\n",
    "                true_positives = confusion_matrix[1][1]\n",
    "                total_observations = len(y_xval_pred)\n",
    "                \n",
    "                print(\"Xval f-score %.3f\" % score)\n",
    "                print(\"Xval F1 %.3f\" % sklearn.metrics.f1_score(y_xval_pred, y_xval))\n",
    "                print(\"Raw error score ----------> %.4f\" % ((false_positives*2 + false_negatives) / float(total_observations)))                \n",
    "\n",
    "print('%s Finishing' % time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# summarize results\n",
    "# print(\"Best: %f using %s\" % (classifier.best_score_, classifier.best_params_))\n",
    "# means = classifier.cv_results_['mean_test_score']\n",
    "# stds = classifier.cv_results_['std_test_score']\n",
    "# params = classifier.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "#print(\"\\nResults: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122994   1386]\n",
      " [   485   1955]]\n",
      "Xval f-score 0.719\n",
      "Xval F1 0.676\n",
      "Raw error score ----------> 0.0186\n",
      "[[123012   1340]\n",
      " [   473   1995]]\n",
      "Test f-score 0.719\n",
      "Test F1 0.688\n",
      "Raw error score ----------> 0.0180\n"
     ]
    }
   ],
   "source": [
    "# select preferred parameters using raw error and f-score\n",
    "\n",
    "hl = 30\n",
    "dr = 0.333\n",
    "rp = 0.00010000\n",
    "cw = {0: 1.0, 1: 2.0}\n",
    "\n",
    "classifier = KerasClassifier(build_fn=create_model, epochs=500, batch_size=500, verbose=0,\n",
    "                             hidden_layer_size=hl, \n",
    "                             dropout=dr, \n",
    "                             reg_penalty=rp,\n",
    "                             class_weight=cw\n",
    "                             )\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_xval_proba = classifier.predict_proba(X_xval)[:,1]\n",
    "thresh, score = selectThreshold(y_xval_proba, y_xval, beta=(2.0/3))\n",
    "y_xval_pred = y_xval_proba >= thresh\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "print(confusion_matrix)\n",
    "true_negatives = confusion_matrix[0][0]\n",
    "false_negatives = confusion_matrix[0][1]\n",
    "false_positives = confusion_matrix[1][0]\n",
    "true_positives = confusion_matrix[1][1]\n",
    "total_observations = len(y_xval_pred)\n",
    "                \n",
    "print(\"Xval f-score %.3f\" % score)\n",
    "print(\"Xval F1 %.3f\" % sklearn.metrics.f1_score(y_xval_pred, y_xval))\n",
    "print(\"Raw error score ----------> %.4f\" % ((false_positives*2 + false_negatives) / float(total_observations)))                \n",
    "\n",
    "y_test_proba = classifier.predict_proba(X_test)[:,1]\n",
    "y_test_pred = y_test_proba >= thresh\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_test_pred, y_test)\n",
    "print(confusion_matrix)\n",
    "true_negatives = confusion_matrix[0][0]\n",
    "false_negatives = confusion_matrix[0][1]\n",
    "false_positives = confusion_matrix[1][0]\n",
    "true_positives = confusion_matrix[1][1]\n",
    "total_observations = len(y_test_pred)\n",
    "\n",
    "print(\"Test f-score %.3f\" % score)\n",
    "print(\"Test F1 %.3f\" % sklearn.metrics.f1_score(y_test_pred, y_test))\n",
    "print(\"Raw error score ----------> %.4f\" % ((false_positives*2 + false_negatives) / float(total_observations)))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
